name: PhoneLM-1.5B-Instruct
wandb: True
resume: False
profile: False
training:
    base_dir: "./checkpoints/PhoneLM-1.5B-Stage2/best_ckpt"
    use_bf16: True
    context_size: 2048
    num_train_epochs: 8
    learning_rate: 2e-5
    adam_beta1: 0.9
    adam_beta2: 0.95
    adam_epsilon: 1e-8
    weight_decay: 0.1
    deepspeed_config: "./ds_config_decaylr.json"
    per_device_train_batch_size: 1024
    per_device_eval_batch_size: 64
    gradient_accumulation_steps: 1
    set_logging_steps: 20
    set_compute_metrics: False
    bad_epochs_limit: 5
    warmup_steps: 1000
    set_eval_steps: 2000
    set_save_steps: 2000
model:
    tokenizer_path: "./tokenizer"  
datasets:
    path: "./train_datasets_instruct"
    val_rate: 0.005
